{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":5448281,"sourceType":"datasetVersion","datasetId":2272599},{"sourceId":8804933,"sourceType":"datasetVersion","datasetId":5295430}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ***Grammar Error Correction***","metadata":{}},{"cell_type":"markdown","source":"# *Downloading required packages*","metadata":{}},{"cell_type":"code","source":"!pip install datasets\n!pip install autocorrect\n!pip install transformers\n!pip install tensorflow\n!pip install numpy\n!pip install pandas \n!pip install sklearn","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Er5AmSQJ7yzi","outputId":"7b770772-b4fb-4cf5-bfb7-bf85ee298104","execution":{"iopub.status.busy":"2024-07-27T10:41:25.791555Z","iopub.execute_input":"2024-07-27T10:41:25.791958Z","iopub.status.idle":"2024-07-27T10:42:45.434975Z","shell.execute_reply.started":"2024-07-27T10:41:25.791932Z","shell.execute_reply":"2024-07-27T10:42:45.433592Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.20.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.13.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.5.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.23.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.7.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nRequirement already satisfied: autocorrect in /opt/conda/lib/python3.10/site-packages (2.6.1)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.42.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.23.4)\nRequirement already satisfied: numpy<2.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.5.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\nRequirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.15.0)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.5.26)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.10.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (16.0.6)\nRequirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.26.4)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (69.0.3)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.9.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.35.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.60.0)\nRequirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.1)\nRequirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.0)\nCollecting keras<2.16,>=2.15.0 (from tensorflow)\n  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.32.3)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow) (3.1.1)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.7.4)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\nDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: keras\n  Attempting uninstall: keras\n    Found existing installation: keras 3.4.1\n    Uninstalling keras-3.4.1:\n      Successfully uninstalled keras-3.4.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed keras-2.15.0\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.26.4)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.2)\nRequirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\nCollecting sklearn\n  Downloading sklearn-0.0.post12.tar.gz (2.6 kB)\n  Preparing metadata (setup.py) ... \u001b[?25lerror\n  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n  \n  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n  \u001b[31m╰─>\u001b[0m \u001b[31m[15 lines of output]\u001b[0m\n  \u001b[31m   \u001b[0m The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n  \u001b[31m   \u001b[0m rather than 'sklearn' for pip commands.\n  \u001b[31m   \u001b[0m \n  \u001b[31m   \u001b[0m Here is how to fix this error in the main use cases:\n  \u001b[31m   \u001b[0m - use 'pip install scikit-learn' rather than 'pip install sklearn'\n  \u001b[31m   \u001b[0m - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n  \u001b[31m   \u001b[0m   (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n  \u001b[31m   \u001b[0m - if the 'sklearn' package is used by one of your dependencies,\n  \u001b[31m   \u001b[0m   it would be great if you take some time to track which package uses\n  \u001b[31m   \u001b[0m   'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n  \u001b[31m   \u001b[0m - as a last resort, set the environment variable\n  \u001b[31m   \u001b[0m   SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n  \u001b[31m   \u001b[0m \n  \u001b[31m   \u001b[0m More information is available at\n  \u001b[31m   \u001b[0m https://github.com/scikit-learn/sklearn-pypi-package\n  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n  \n  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n\n\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n\u001b[31m╰─>\u001b[0m See above for output.\n\n\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n\u001b[1;36mhint\u001b[0m: See above for details.\n\u001b[?25h","output_type":"stream"}]},{"cell_type":"markdown","source":"# *Importing packages*","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom transformers import AdamW,T5ForConditionalGeneration,T5Tokenizer\nfrom sklearn.model_selection import train_test_split\nfrom autocorrect import Speller","metadata":{"id":"EbrQ4lPPre5l","execution":{"iopub.status.busy":"2024-07-27T09:59:19.960517Z","iopub.execute_input":"2024-07-27T09:59:19.960933Z","iopub.status.idle":"2024-07-27T09:59:19.966061Z","shell.execute_reply.started":"2024-07-27T09:59:19.960897Z","shell.execute_reply":"2024-07-27T09:59:19.965158Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# *Setting seeding*","metadata":{}},{"cell_type":"code","source":"def set_seed(seed):\n  tf.random.set_seed(seed)\n  np.random.seed(seed)\n\nset_seed(42)","metadata":{"id":"Gdi5X-WHrw2B","execution":{"iopub.status.busy":"2024-07-27T09:59:19.967362Z","iopub.execute_input":"2024-07-27T09:59:19.967668Z","iopub.status.idle":"2024-07-27T09:59:19.977516Z","shell.execute_reply.started":"2024-07-27T09:59:19.967646Z","shell.execute_reply":"2024-07-27T09:59:19.976701Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# *Loading C4 200M dataset*","metadata":{}},{"cell_type":"code","source":"pd.set_option('display.max_colwidth', None)\n\ncolumn_names = ['input','output']\ndf = pd.read_csv('/kaggle/input/c4200m/C4_200M.tsv-00000-of-00010',sep = '\\t',names=column_names, header=None)\ndf = df.drop(df.index[0])","metadata":{"id":"D7IfBiGYsGZN","execution":{"iopub.status.busy":"2024-07-27T09:59:19.980081Z","iopub.execute_input":"2024-07-27T09:59:19.980475Z","iopub.status.idle":"2024-07-27T10:01:38.923843Z","shell.execute_reply.started":"2024-07-27T09:59:19.980445Z","shell.execute_reply":"2024-07-27T10:01:38.923040Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df = df[:10000]\ndf.head()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"Y8DI9SghsOFC","outputId":"f1a1d6a1-4425-4883-e204-bae5f0de8b8c","execution":{"iopub.status.busy":"2024-07-27T10:01:38.924912Z","iopub.execute_input":"2024-07-27T10:01:38.925217Z","iopub.status.idle":"2024-07-27T10:01:38.944651Z","shell.execute_reply.started":"2024-07-27T10:01:38.925192Z","shell.execute_reply":"2024-07-27T10:01:38.943641Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                                                                                                                                                                                                                                                                                                                            input  \\\n1                                                                                                                                                                                                                                                         The effect of widespread dud targets two face up attack position monsters on the field.   \n2  tax on sales of stores for non residents are set at 21% for 2014 and 20% in 2015 payable on sales tentatively earned from the difference of the property value some time of purchase (price differences according to working time) and theyear to which sale couples (sales costs), based on the approved annual on the base approved by law).   \n3                                                                                                                                                                                                                                                                                               Much many brands and sellers still in the market.   \n4                                                                                                                                                                                                                                                                                          this is is the latest Maintenance release of Samba 3.6   \n5                                                                                                                                                                                                                                                  Fairy Or Not, I'm the Godmother: no just look, but my outfit for taking the part as godmother.   \n\n                                                                                                                                                                                                                                                                                                                                                                output  \n1                                                                                                                                                                                                                                                                         1. The effect of \"widespread dud\" targets two face up attack position monsters on the field.  \n2  Capital Gains tax on the sale of properties for non-residents is set at 21% for 2014 and 20% in 2015 payable on profits earned on the difference of the property value between the year of purchase (purchase price plus costs) and the year of sale (sales price minus costs), based on the approved annual percentage increase on the base value approved by law.  \n3                                                                                                                                                                                                                                                                                                                         Many brands and sellers still in the market.  \n4                                                                                                                                                                                                                                                                                                              This is is the latest maintenance release of Samba 3.6.  \n5                                                                                                                                                                                                                                                                 Fairy Or Not, I'm the Godmother: Not just a look, but my outfit for taking on the role as godmother.  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>input</th>\n      <th>output</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>The effect of widespread dud targets two face up attack position monsters on the field.</td>\n      <td>1. The effect of \"widespread dud\" targets two face up attack position monsters on the field.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>tax on sales of stores for non residents are set at 21% for 2014 and 20% in 2015 payable on sales tentatively earned from the difference of the property value some time of purchase (price differences according to working time) and theyear to which sale couples (sales costs), based on the approved annual on the base approved by law).</td>\n      <td>Capital Gains tax on the sale of properties for non-residents is set at 21% for 2014 and 20% in 2015 payable on profits earned on the difference of the property value between the year of purchase (purchase price plus costs) and the year of sale (sales price minus costs), based on the approved annual percentage increase on the base value approved by law.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Much many brands and sellers still in the market.</td>\n      <td>Many brands and sellers still in the market.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>this is is the latest Maintenance release of Samba 3.6</td>\n      <td>This is is the latest maintenance release of Samba 3.6.</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Fairy Or Not, I'm the Godmother: no just look, but my outfit for taking the part as godmother.</td>\n      <td>Fairy Or Not, I'm the Godmother: Not just a look, but my outfit for taking on the role as godmother.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# *Initializing the model*","metadata":{}},{"cell_type":"code","source":"from transformers import TFT5ForConditionalGeneration,T5Tokenizer\n\nmodel_name = 't5-small'\ntokenizer = T5Tokenizer.from_pretrained(model_name)\nmodel = TFT5ForConditionalGeneration.from_pretrained(model_name)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LMHh5dnwsnaa","outputId":"607f000c-2d5e-44e8-d5f1-7de657b05db4","execution":{"iopub.status.busy":"2024-07-27T10:01:38.945846Z","iopub.execute_input":"2024-07-27T10:01:38.946142Z","iopub.status.idle":"2024-07-27T10:01:52.956380Z","shell.execute_reply.started":"2024-07-27T10:01:38.946088Z","shell.execute_reply":"2024-07-27T10:01:52.955581Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d76cd866d6884c10b4bc9fa51406d536"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2068821a707544e7b71d6506f33f112e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba402c796f294c958d3cd45bf2d1e002"}},"metadata":{}},{"name":"stderr","text":"You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebe616a5aa564b3492d5e59c1b2df50c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65e262cc212c48618423b14f84798365"}},"metadata":{}},{"name":"stderr","text":"All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n\nAll the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# *Preprocessing the dataframe*","metadata":{}},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ywftQPlME1dE","outputId":"abb57b19-a493-489c-ffa8-b641422014a9","execution":{"iopub.status.busy":"2024-07-27T10:01:52.957521Z","iopub.execute_input":"2024-07-27T10:01:52.957826Z","iopub.status.idle":"2024-07-27T10:01:52.969493Z","shell.execute_reply.started":"2024-07-27T10:01:52.957802Z","shell.execute_reply":"2024-07-27T10:01:52.968606Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"input     0\noutput    0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df.fillna('', inplace=True)","metadata":{"id":"c_sijhaUE9VR","execution":{"iopub.status.busy":"2024-07-27T10:01:52.970677Z","iopub.execute_input":"2024-07-27T10:01:52.970928Z","iopub.status.idle":"2024-07-27T10:01:52.982414Z","shell.execute_reply.started":"2024-07-27T10:01:52.970908Z","shell.execute_reply":"2024-07-27T10:01:52.981541Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Making a list of strings\nuncorrected = df['input'].astype(str) \ncorrected = df['output'].astype(str)\n\n# Tokenizing the text of every \ntokenized_input = tokenizer(uncorrected.tolist(), padding=True, truncation=True, return_tensors='tf')\ntokenized_output = tokenizer(corrected.tolist(), padding=True, truncation=True, return_tensors='tf')\n\n# making list of input_ids and attention masks \nX_input_ids = tokenized_input['input_ids'].numpy()\nY_input_ids = tokenized_output['input_ids'].numpy()\nX_attention_mask = tokenized_input['attention_mask'].numpy()\nY_attention_mask = tokenized_output['attention_mask'].numpy()","metadata":{"id":"jzgzGQBtzUqu","execution":{"iopub.status.busy":"2024-07-27T10:01:52.983549Z","iopub.execute_input":"2024-07-27T10:01:52.983869Z","iopub.status.idle":"2024-07-27T10:01:58.177043Z","shell.execute_reply.started":"2024-07-27T10:01:52.983846Z","shell.execute_reply":"2024-07-27T10:01:58.176275Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Splitting the numpy array into train, validation and test of inputs and outputs \nX_train, X_test, Y_train, Y_test = train_test_split(X_input_ids, Y_input_ids, test_size=0.1, random_state=42)\nx_train, x_val, y_train, y_val = train_test_split(X_train,Y_train,test_size = 0.1, random_state = 42)\nX_train_attention_mask, X_test_attention_mask, Y_train_attention_mask, Y_test_attention_mask = train_test_split(X_attention_mask, Y_attention_mask, test_size=0.1, random_state=42)\nx_train_attention_mask, x_val_attention_mask, y_train_attention_mask, y_val_attention_mask = train_test_split(X_train_attention_mask, Y_train_attention_mask, test_size=0.1, random_state=42)\n\n# Making a input model directory \nmodel_input = {\n    'input_ids': x_train,\n    'attention_mask': x_train_attention_mask,\n    'labels': y_train\n}\n","metadata":{"id":"IG3OE4ERFfvb","execution":{"iopub.status.busy":"2024-07-27T10:01:58.179757Z","iopub.execute_input":"2024-07-27T10:01:58.180048Z","iopub.status.idle":"2024-07-27T10:01:58.248470Z","shell.execute_reply.started":"2024-07-27T10:01:58.180024Z","shell.execute_reply":"2024-07-27T10:01:58.247310Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{"id":"tTYTsmRwTAGB"}},{"cell_type":"markdown","source":"# *Compiling and Training the model*","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\n\nstrategy = tf.distribute.MirroredStrategy()   # used for running the processes simulteneously on multiple GPUs\nwith strategy.scope():\n    model_name = 't5-small' \n    model = TFT5ForConditionalGeneration.from_pretrained(model_name)\n    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(          # Defining a loss function\n        from_logits=True, reduction=tf.keras.losses.Reduction.SUM     # sums up the losses      \n    )\n    model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy']) # compling ","metadata":{"id":"zOMKO4SpQjVY","colab":{"base_uri":"https://localhost:8080/"},"outputId":"02709349-8de3-4f9b-a285-7cf2e3b1112e","execution":{"iopub.status.busy":"2024-07-27T10:01:58.249684Z","iopub.execute_input":"2024-07-27T10:01:58.249993Z","iopub.status.idle":"2024-07-27T10:02:06.093758Z","shell.execute_reply.started":"2024-07-27T10:01:58.249958Z","shell.execute_reply":"2024-07-27T10:02:06.093010Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d551f38896604909bac38b9396ef91d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29fe7a52a39848d1a1704260e2c5f4b4"}},"metadata":{}},{"name":"stderr","text":"All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n\nAll the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# *Making 3 datasets : Train, test and validation*","metadata":{}},{"cell_type":"code","source":"batch_size = 16 # defining the size of one batch\n\ntrain_dataset = tf.data.Dataset.from_tensor_slices((\n    {\n        'input_ids': model_input['input_ids'],\n        'attention_mask': model_input['attention_mask'],\n        'labels': model_input['labels']\n    }\n)).batch(batch_size)\n\nval_dataset = tf.data.Dataset.from_tensor_slices((\n    {\n        'input_ids': X_test,\n        'attention_mask': X_test_attention_mask,\n        'labels': Y_test\n    }\n)).batch(batch_size)\n\ntest_dataset = tf.data.Dataset.from_tensor_slices((\n    {\n        'input_ids': X_test,\n        'attention_mask': X_test_attention_mask,\n        'labels': Y_test\n    }\n)).batch(batch_size)","metadata":{"id":"KFwinZVhSIZr","execution":{"iopub.status.busy":"2024-07-27T10:02:06.094922Z","iopub.execute_input":"2024-07-27T10:02:06.095241Z","iopub.status.idle":"2024-07-27T10:02:06.153799Z","shell.execute_reply.started":"2024-07-27T10:02:06.095217Z","shell.execute_reply":"2024-07-27T10:02:06.152840Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# *Training the model*","metadata":{}},{"cell_type":"code","source":"model.fit(\n    train_dataset,\n    validation_data=val_dataset,\n    epochs=3\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3ydmXOPaSkjm","outputId":"7032f4cb-7990-4292-825d-758c33aed1e7","execution":{"iopub.status.busy":"2024-07-27T10:02:06.155236Z","iopub.execute_input":"2024-07-27T10:02:06.155998Z","iopub.status.idle":"2024-07-27T10:21:49.036152Z","shell.execute_reply.started":"2024-07-27T10:02:06.155966Z","shell.execute_reply":"2024-07-27T10:21:49.035285Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Epoch 1/3\nWARNING: AutoGraph could not transform <function infer_framework at 0x789f58305000> and will run it as-is.\nCause: for/else statement not yet supported\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1722074609.398904     136 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"507/507 [==============================] - 467s 741ms/step - loss: 886.8325 - accuracy: 0.9760 - val_loss: 410.2971 - val_accuracy: 0.9853\nEpoch 2/3\n507/507 [==============================] - 357s 705ms/step - loss: 417.7831 - accuracy: 0.9848 - val_loss: 401.5069 - val_accuracy: 0.9857\nEpoch 3/3\n507/507 [==============================] - 358s 706ms/step - loss: 365.7963 - accuracy: 0.9861 - val_loss: 404.8884 - val_accuracy: 0.9858\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"<tf_keras.src.callbacks.History at 0x789f4c33a830>"},"metadata":{}}]},{"cell_type":"markdown","source":"# *Testing*","metadata":{}},{"cell_type":"code","source":"test_loss, test_accuracy = model.evaluate(test_dataset) \nprint(f'Test loss: {test_loss}')\nprint(f'Test accuracy: {test_accuracy}')","metadata":{"id":"YObavR1513TZ","outputId":"146ffbd3-3c0e-4868-ee7a-766004bab440","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-07-27T10:21:49.037201Z","iopub.execute_input":"2024-07-27T10:21:49.037472Z","iopub.status.idle":"2024-07-27T10:22:05.707597Z","shell.execute_reply.started":"2024-07-27T10:21:49.037442Z","shell.execute_reply":"2024-07-27T10:22:05.706567Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"63/63 [==============================] - 17s 262ms/step - loss: 404.8884 - accuracy: 0.9858\nTest loss: 404.888427734375\nTest accuracy: 0.9858379364013672\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# *Spelling correction*","metadata":{}},{"cell_type":"code","source":"from autocorrect import Speller\n\nspell = Speller(lang='en')\n\ndef correct_spelling(text):\n    return spell(text)","metadata":{"id":"nCiC3rpR23Pj","execution":{"iopub.status.busy":"2024-07-27T10:22:05.708768Z","iopub.execute_input":"2024-07-27T10:22:05.709599Z","iopub.status.idle":"2024-07-27T10:22:05.790537Z","shell.execute_reply.started":"2024-07-27T10:22:05.709572Z","shell.execute_reply":"2024-07-27T10:22:05.789551Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"# *Generating output function*","metadata":{}},{"cell_type":"code","source":"def generate_output(model, tokenizer, input_text):\n    input_tokens = tokenizer.encode(input_text, return_tensors='tf')\n\n    output_tokens = model.generate(input_ids=input_tokens, max_length=50)\n\n    output_text = tokenizer.decode(output_tokens[0], skip_special_tokens=True)\n\n    return correct_spelling(output_text)\n\ninput_text = input()\noutput_text = generate_output(model, tokenizer, input_text)\nprint(\"Input Text: \", input_text)\nprint(\"Output Text: \", output_text)","metadata":{"id":"7uwuvNCt13TZ","outputId":"a5248a42-d8a8-4ce9-9ae4-280cbd71fb05","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-07-27T10:22:05.792737Z","iopub.execute_input":"2024-07-27T10:22:05.793044Z","iopub.status.idle":"2024-07-27T10:23:28.383722Z","shell.execute_reply.started":"2024-07-27T10:22:05.793018Z","shell.execute_reply":"2024-07-27T10:23:28.382776Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdin","text":" I is playing football and I believe that I would be the better at it.\n"},{"name":"stdout","text":"Input Text:  I is playing football and I believe that I would be the better at it.\nOutput Text:  I am playing football and I believe that I would be the better at it.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Saving the model for future use","metadata":{}},{"cell_type":"code","source":"model.save_weights('GEC.h5')","metadata":{"id":"ozRLNefF13Ta","colab":{"base_uri":"https://localhost:8080/","height":408},"outputId":"0183fd21-6880-41c8-a3ac-b5b2cf715df0","execution":{"iopub.status.busy":"2024-07-27T10:54:41.448897Z","iopub.execute_input":"2024-07-27T10:54:41.449342Z","iopub.status.idle":"2024-07-27T10:54:42.519386Z","shell.execute_reply.started":"2024-07-27T10:54:41.449309Z","shell.execute_reply":"2024-07-27T10:54:42.518336Z"},"trusted":true},"execution_count":23,"outputs":[]}]}
